{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, time, os, gc\n",
    "from datetime import datetime, date \n",
    "\n",
    "from sklearn import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#from sklearn import model_selection\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import seaborn as sns, matplotlib, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set working directory\n",
    "os.chdir(r\"C:\\Users\\anupr\\Desktop\\Two Sigma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "marketing_train = pd.read_csv(\"marketdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputMarketObservationFilter = [\"volume\", \"close\", \"open\", \n",
    "                                \"returnsClosePrevRaw1\", \"returnsOpenPrevRaw1\", \n",
    "                                \"returnsClosePrevMktres1\", \"returnsOpenPrevMktres1\", \n",
    "                                \"returnsClosePrevRaw10\", \"returnsOpenPrevRaw10\", \n",
    "                                \"returnsClosePrevMktres10\", \"returnsOpenPrevMktres10\"]\n",
    "\n",
    "inputNewsObservationFilter = [\"relevance\", \"sentimentNegative\", \"sentimentNeutral\", \"sentimentPositive\"]\n",
    "\n",
    "paramLagFeatures = ['returnsClosePrevMktres10','returnsClosePrevMktres1']\n",
    "paramLagFrequencies = [3,7,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreloadMarketTrainingRaw():\n",
    "    mandatoryColumns =  [\"time\", \"assetCode\", \"universe\", 'returnsOpenNextMktres10']\n",
    "    returnColumns = mandatoryColumns + inputMarketObservationFilter\n",
    "    marketRaw = env.get_training_data()[0][returnColumns]\n",
    "\n",
    "    #marketRaw['time'] = marketRaw.time.dt.date\n",
    "    marketRaw['volume'] = pd.to_numeric(marketRaw.volume, errors='coerce', downcast='integer')\n",
    "    marketRaw['universe'] = pd.to_numeric(marketRaw.universe, errors='coerce', downcast='integer')\n",
    "    real = {c: 'float16' for c in marketRaw.columns if c not in ['assetCode', 'time', \"volume\", \"universe\"]}\n",
    "    return marketRaw.astype(real)\n",
    "\n",
    "def PreloadNewsTrainingRaw():\n",
    "    mandatoryColumns =  [\"time\", \"assetCodes\"]\n",
    "    returnColumns = mandatoryColumns + inputNewsObservationFilter\n",
    "    newsRaw = env.get_training_data()[1][returnColumns]\n",
    "    #newsRaw['time'] = newsRaw.time.dt.date\n",
    "    return newsRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConsolidateMarket(inputMarket):\n",
    "    mandatoryColumns =  [\"time\", \"assetCode\"]\n",
    "    cols = mandatoryColumns + inputMarketObservationFilter\n",
    "    \n",
    "    # append target when available\n",
    "    if 'returnsOpenNextMktres10' in inputMarket.columns:\n",
    "        cols = cols + ['returnsOpenNextMktres10']\n",
    "    \n",
    "    output = inputMarket[cols].reset_index()\n",
    "    output['time'] = output.time.dt.date\n",
    "    \n",
    "    output['returnsClose'] = (output['close'] / output['open'])-1\n",
    "    #output['volume'] = pd.to_numeric(output.volume, errors='coerce', downcast='integer')\n",
    "    #output['returnsClose'] = pd.to_numeric(output.returnsClose, errors='coerce', downcast='float')\n",
    "    output.dropna(axis=0, inplace=True)\n",
    "   \n",
    "    dropColumns = [\"close\", \"open\", \"index\"]\n",
    "    output.drop(dropColumns, axis=1, inplace=True)\n",
    "\n",
    "    aggregations = ['mean']\n",
    "    gp = output.groupby(['assetCode', 'time']).agg(aggregations)\n",
    "    gp.columns = pd.Index([\"{}\".format(e[0]) for e in gp.columns.tolist()])\n",
    "    gp.reset_index(inplace=True)\n",
    "    \n",
    "    real = {c: 'float16' for c in output.columns if c not in ['assetCode', 'time', \"universe\", \"volume\"]}\n",
    "    return gp.astype(real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEWS Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to decompose assetcodes\n",
    "def MetaBuildNewsAssetCodeIndex(inputNews):\n",
    "    codes = []\n",
    "    indexes = []\n",
    "    for i, values in inputNews['assetCodes'].iteritems():\n",
    "        explode = values.split(\", \")\n",
    "        codes.extend(explode)\n",
    "        repeat_index = [int(i)]*len(explode)\n",
    "        indexes.extend(repeat_index)\n",
    "    output = pd.DataFrame({'ID': indexes, 'assetCode': codes})\n",
    "    output[\"ID\"] = pd.to_numeric(output[\"ID\"], errors='coerce', downcast='integer')\n",
    "    del codes, indexes\n",
    "    gc.collect()\n",
    "    return output\n",
    "\n",
    "\n",
    "# denormalising assetcodes into assetCode column which serves as foreign key to market assetCode\n",
    "def MetaBuildIndexedNews(inputNews):\n",
    "    inputNews['ID'] = inputNews.index.copy()\n",
    "    inputNews['assetCodes'] = inputNews['assetCodes'].apply(lambda x: x[1:-1].replace(\"'\", \"\"))\n",
    "    # Merge news on unstacked assets\n",
    "    output = MetaBuildNewsAssetCodeIndex(inputNews).merge(inputNews, how='left', on='ID')\n",
    "    output.drop(['ID', 'assetCodes'], axis=1, inplace=True)\n",
    "    return output\n",
    "\n",
    "\n",
    "## Comine multiple news reports for same assets on same day.\n",
    "def MetaGroupByDay(inputNews):\n",
    "    aggregations = ['mean']\n",
    "    gp = inputNews.groupby(['assetCode', 'time']).agg(aggregations)\n",
    "    gp.columns = pd.Index([\"{}\".format(e[0]) for e in gp.columns.tolist()])\n",
    "    gp.reset_index(inplace=True)\n",
    "    # Set datatype to float16\n",
    "    real = {c: 'float16' for c in gp.columns if c not in ['assetCode', 'time', 'volume']}\n",
    "    return gp.astype(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting it all together\n",
    "def ConsolidateNews(inputNews):\n",
    "    mandatoryColumns =  [\"time\", \"assetCodes\"]\n",
    "    cols = mandatoryColumns + inputNewsObservationFilter\n",
    "    \n",
    "    output = inputNews[cols].reset_index()\n",
    "    output['time'] = output.time.dt.date\n",
    "    \n",
    "    output[\"SentimentCoefficient\"] = (output.sentimentPositive - output.sentimentNegative) * (1-output.sentimentNeutral)\n",
    "\n",
    "    \n",
    "    dropColumns = [\"index\", \"sentimentPositive\", \"sentimentNegative\", \"sentimentNeutral\"]\n",
    "    output.drop(dropColumns, axis=1, inplace=True)\n",
    "    \n",
    "    idxn = MetaBuildIndexedNews(output)\n",
    "    output = MetaGroupByDay(idxn)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cNews = ConsolidateNews(PreloadNewsTrainingRaw()) cNews.head() cNews.info() del cMarket, cNews gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConsolidateMarketNews(inputMarketRaw, inputNewsRaw):   \n",
    "        return ConsolidateMarket(inputMarketRaw).merge(ConsolidateNews(inputNewsRaw), how='left', on=['time','assetCode']).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variation 1: template processing using Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## enter transformationlogic here \n",
    "\n",
    "## adjust derived features to transformation logic\n",
    "derivedFeatures = ['returnsClose', 'returnsOpenPrevMktres10', 'returnsClosePrevMktres10', 'SentimentCoefficient']\n",
    "\n",
    "outputFeatureSet = cmn[derivedFeatures]\n",
    "outputTag = [] # target label for training, assetCode for prediction\n",
    "\n",
    "if 'returnsOpenNextMktres10' in cmn.columns:\n",
    "    outputTag = (cmn.returnsOpenNextMktres10 >= 0).astype('int8')\n",
    "else:\n",
    "    outputTag = cmn.assetCode\n",
    "\n",
    "return outputFeatureSet, outputTag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best parameters found.\n",
    "V1Model = LGBMClassifier( objective='binary', boosting='gbdt', learning_rate = 0.05, max_depth = 8, num_leaves = 80, n_estimators = 400, bagging_fraction = 0.8, feature_fraction = 0.9)# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Variation 2: template processing using Sentiment\n",
    "\n",
    "def V2Ingest(inputMarketRaw,inputNewsRaw):\n",
    "    cmn = ConsolidateMarketNews(inputMarketRaw, inputNewsRaw)\n",
    "    \n",
    "    ## enter transformationlogic here \n",
    "    cmn[\"SentimentWeighted\"] = cmn.relevance * cmn.SentimentCoefficient\n",
    "    ## adjust derived features to transformation logic\n",
    "    \n",
    "    derivedFeatures = ['returnsClose', 'returnsOpenPrevMktres10', 'SentimentWeighted']\n",
    "    \n",
    "    outputFeatureSet = cmn[derivedFeatures]\n",
    "    outputTag = [] # target label for training, assetCode for prediction\n",
    "    \n",
    "    if 'returnsOpenNextMktres10' in cmn.columns:\n",
    "        outputTag = (cmn.returnsOpenNextMktres10 >= 0).astype('int8')\n",
    "    else:\n",
    "        outputTag = cmn.assetCode\n",
    "    \n",
    "    return outputFeatureSet, outputTag\n",
    "\n",
    "# Training\n",
    "featureSet, target = V2Ingest(PreloadMarketTrainingRaw(), PreloadNewsTrainingRaw())\n",
    "\n",
    "#featureSet.head()\n",
    "#target.describe()\n",
    "## best parameters found.\n",
    "V2Model = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    boosting='gbdt',\n",
    "    learning_rate = 0.05,\n",
    "    max_depth = 8,\n",
    "    num_leaves = 80,\n",
    "    n_estimators = 400,\n",
    "    bagging_fraction = 0.8,\n",
    "    feature_fraction = 0.9)\n",
    "    #reg_alpha = 0.2,\n",
    "    #reg_lambda = 0.4)\n",
    "    \n",
    "V2Model.fit(featureSet, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "days = env.get_prediction_days()\n",
    "n_days = 0\n",
    "\n",
    "for (market_obs_df, news_obs_df, predictions_template_df) in days:\n",
    "    n_days += 1\n",
    "    print(n_days,end=' ')\n",
    "    \n",
    "    # adjust block to select VxIngest and models\n",
    "    featureSet, assetCode = V2Ingest(market_obs_df, news_obs_df)\n",
    "    preds = V2Model.predict_proba(featureSet)[:, 1] * 2 - 1\n",
    "    \n",
    "    sub = pd.DataFrame({'assetCode': assetCode, 'confidence': preds})\n",
    "    predictions_template_df = predictions_template_df.merge(sub, how='left').drop(\n",
    "        'confidenceValue', axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n",
    "\n",
    "    env.predict(predictions_template_df)\n",
    "\n",
    "print('Prediction Complete!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
